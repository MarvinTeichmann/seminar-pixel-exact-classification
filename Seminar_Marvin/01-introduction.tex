%!TEX root = vorlage.tex
% Marvin Teichmann and Martin Thoma
\section{Introduction}\label{sec:introduction}

In 2012 Krizhevsky et. al \cite{AlexNet} won with a new Architecture of CNN's ILSVRC-2012, the ImageNet Classification Challenge by an order of a magnitude. The surprising success marked the beginning of a Renaissance of deep CNN's in Computer Vision. Since than deep CNN's have broken new records in almost any domain of Computer Vision including Classification \cite{AlexNet,VGG16,googLeNeT}, Localization and Detection \cite{RNN,overfeat} and Segmentation \cite{fcn,CRF1,googleSeg}.

TODO:
\begin{itemize}
\item some motivation  describing the purpose of this paper
\item explain relevants of semantic segmentation in Medical Informatics
\item Reference to Martin
\end{itemize}
%TODO: Describing the purpose of this paper.

This paper is structured as fellows: \cref{sec:tasks} defines the most common Computer Visions Tasks and there relations. \cref{sec:cnn} briefly explains the mechanics of CNN's and gives a short overview of the most commonly used architectures. \Cref{sec:fcn} describes recent results in Semantic Segmentation using \Glspl{DCNN}. Finally \Cref{sec:application} outlines how this techniques can be applied on current challenges in Medical Informatics.


\section{Computer Vision Tasks} \label{sec:tasks}

Three very important Computer Vision Tasks are \emph{Classification}, \emph{Detection} and \emph{Semantic Segmentation}. All of the three task have as input a single image, but differ in the expected output.

TODO: Finish paragraph

\iffalse

\section{Historical Review}\label{sec:review}



Krizhevsky et. al \cite{AlexNet} won the .

AlexNet was improved by several Authors in the succeeding years to achieve even better classification results in the ILSVRC-2013 and 2014. Most notable are GoogLeNet \cite{googLeNeT} and VGG16 \cite{VGG16}. Being designed independently, both Networks utilize filters with very small kernel size ($3\times 3$ and $1 \times 1$) and other parameter reduction techniques in order to severely increase the depths of their network.


\cite{AlexNet} al introduced a novel \gls{CNN} architecture. 

\fi







