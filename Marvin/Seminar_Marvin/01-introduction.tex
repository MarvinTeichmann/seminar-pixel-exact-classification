%!TEX root = vorlage.tex
% Marvin Teichmann and Martin Thoma
\section{Introduction}\label{sec:introduction}

In 2012 Krizhevsky et. al \cite{AlexNet} won with a new Architekture of CNNs ILSVRC-2012, the ImageNet Classification Challange by an order of a magnitude. The surprising success marked the beginning of a renessounce of deep CNNs in Computer Vision. Since than deep CNNs have broken new records in almost any domain of Computer Vision including Classification \cite{AlexNet,VGG16,googLeNeT}, Localization and Detection \cite{RNN,overfeat} and Segmentation \cite{fcn,CRF1,googleSeg}.

%TODO: Describing the purpose of this paper.

This paper is structered as fellows: \cref{sec:tasks} defines the most common Computer Visions Tasks and there relations. \cref{sec:cnn} briefly explains the mechanics of CNNs and gives a short overview of the most commonly used architectures. \Cref{sec:fcn} descripes recent results in Semantic Segmentation using \Glspl{DCNN}. Finally \Cref{sec:application} outlines how this techniques can be applied on current challenges in medical informatics.


\section{Computer Vision Tasks} \label{sec:tasks}

Three very important Computer Vision Tasks are \emph{Classification}, \emph{Detection} and \emph{Semantic Segmentation}. All of the three task have as input a single image, but differ in the expected output.

\iffalse

\section{Historical Review}\label{sec:review}



Krizhevsky et. al \cite{AlexNet} won the .

AlexNet was improved by several Authors in the succeeding years to archieve even better classification results in the ILSVRC-2013 and 2014. Most notable are GoogLeNet \cite{googLeNeT} and VGG16 \cite{VGG16}. Beeing designed independently, both Networks utilize filters with very small kernel size ($3\times 3$ and $1 \times 1$) and other parameter reduction techniques in order to severely increase the deepth of their network.


\cite{AlexNet} al introduced a novel \gls{CNN} architecture. 

\fi







